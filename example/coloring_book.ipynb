{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f938540",
   "metadata": {},
   "source": [
    "# MLOps Coloring Book\n",
    "\n",
    "This notebook may be used for demonstration of AutoMLOps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e4d190",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94451868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/srastatter/Documents/2023/MLOps-graduation/AutoMLOps/dist/AutoMLOps-1.0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyflakes==3.0.1 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from AutoMLOps==1.0.0) (3.0.1)\n",
      "Requirement already satisfied: yarg==0.1.9 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from AutoMLOps==1.0.0) (0.1.9)\n",
      "Requirement already satisfied: docopt==0.6.2 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from AutoMLOps==1.0.0) (0.6.2)\n",
      "Requirement already satisfied: PyYAML==5.4.1 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from AutoMLOps==1.0.0) (5.4.1)\n",
      "Requirement already satisfied: ipython==7.34.0 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from AutoMLOps==1.0.0) (7.34.0)\n",
      "Requirement already satisfied: autoflake==2.0.0 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from AutoMLOps==1.0.0) (2.0.0)\n",
      "Requirement already satisfied: pipreqs==0.4.11 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from AutoMLOps==1.0.0) (0.4.11)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from autoflake==2.0.0->AutoMLOps==1.0.0) (2.0.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from ipython==7.34.0->AutoMLOps==1.0.0) (3.0.31)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from ipython==7.34.0->AutoMLOps==1.0.0) (5.4.0)\n",
      "Requirement already satisfied: pickleshare in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from ipython==7.34.0->AutoMLOps==1.0.0) (0.7.5)\n",
      "Requirement already satisfied: decorator in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from ipython==7.34.0->AutoMLOps==1.0.0) (5.1.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from ipython==7.34.0->AutoMLOps==1.0.0) (4.8.0)\n",
      "Requirement already satisfied: backcall in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from ipython==7.34.0->AutoMLOps==1.0.0) (0.2.0)\n",
      "Requirement already satisfied: appnope in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from ipython==7.34.0->AutoMLOps==1.0.0) (0.1.3)\n",
      "Requirement already satisfied: pygments in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from ipython==7.34.0->AutoMLOps==1.0.0) (2.13.0)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from ipython==7.34.0->AutoMLOps==1.0.0) (0.1.6)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from ipython==7.34.0->AutoMLOps==1.0.0) (0.18.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from ipython==7.34.0->AutoMLOps==1.0.0) (58.0.4)\n",
      "Requirement already satisfied: requests in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from yarg==0.1.9->AutoMLOps==1.0.0) (2.28.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from jedi>=0.16->ipython==7.34.0->AutoMLOps==1.0.0) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from pexpect>4.3->ipython==7.34.0->AutoMLOps==1.0.0) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.34.0->AutoMLOps==1.0.0) (0.2.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from requests->yarg==0.1.9->AutoMLOps==1.0.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from requests->yarg==0.1.9->AutoMLOps==1.0.0) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from requests->yarg==0.1.9->AutoMLOps==1.0.0) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/srastatter/Library/Python/3.9/lib/python/site-packages (from requests->yarg==0.1.9->AutoMLOps==1.0.0) (2022.9.24)\n",
      "Installing collected packages: AutoMLOps\n",
      "Successfully installed AutoMLOps-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install ../dist/AutoMLOps-1.0.0-py2.py3-none-any.whl --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17db55d5",
   "metadata": {},
   "source": [
    "Restart the kernel after installing the package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503f4a85-c357-4ec4-8ea5-0eeb2c8afd39",
   "metadata": {},
   "source": [
    "# Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28557b2d-598c-466b-8116-bc1e34ba090d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset automlops-sandbox.test_dataset already exists\n",
      "Table test_dataset.dry-beans already exists\n"
     ]
    }
   ],
   "source": [
    "!python3 -m data.load_data_to_bq --project automlops-sandbox --file data/Dry_Beans_Dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3fe994",
   "metadata": {},
   "source": [
    "## 1. Without Using KFP Spec\n",
    "This workflow will generate a pipeline without using Kubeflow spec. `generate()` will create all the necessary files but not run them. `run()` will create all the necessary files, resources, and then push the code to the source repo to trigger the build. Please view the readme for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2219ee67",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd5ac7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AutoMLOps import AutoMLOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "164ff1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%define_imports\n",
    "import json\n",
    "import pandas as pd\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "import datetime\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac0c712-acdd-4830-a9bd-44f41eaa590c",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94a96074-761f-40f0-84bb-adfcb9bf6911",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%define_component\n",
    "AutoMLOps.makeComponent(\n",
    "    name=\"create_dataset\",\n",
    "    description=\"Loads data from BQ and writes a dataframe as a csv to GCS.\", # optional\n",
    "    params=[\n",
    "        {\"name\": \"bq_table\", \"type\": str}, # descriptions are optional\n",
    "        {\"name\": \"data_path\", \"type\": str, \"description\": \"GS location where the training data is written.\"},\n",
    "        {\"name\": \"project_id\", \"type\": str, \"description\": \"Project_id.\"}\n",
    "    ]\n",
    ")\n",
    "# Component code goes below:\n",
    "bq_client = bigquery.Client(project=project_id)\n",
    "\n",
    "def get_query(bq_input_table: str) -> str:\n",
    "    \"\"\"Generates BQ Query to read data.\n",
    "\n",
    "    Args:\n",
    "    bq_input_table: The full name of the bq input table to be read into\n",
    "    the dataframe (e.g. <project>.<dataset>.<table>)\n",
    "    Returns: A BQ query string.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "    SELECT *\n",
    "    FROM `{bq_input_table}`\n",
    "    \"\"\"\n",
    "\n",
    "def load_bq_data(query: str, client: bigquery.Client) -> pd.DataFrame:\n",
    "    \"\"\"Loads data from bq into a Pandas Dataframe for EDA.\n",
    "    Args:\n",
    "    query: BQ Query to generate data.\n",
    "    client: BQ Client used to execute query.\n",
    "    Returns:\n",
    "    pd.DataFrame: A dataframe with the requested data.\n",
    "    \"\"\"\n",
    "    df = client.query(query).to_dataframe()\n",
    "    return df\n",
    "\n",
    "dataframe = load_bq_data(get_query(bq_table), bq_client)\n",
    "dataframe.to_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4476cb4-91c5-42ff-a500-8cc275fedbd1",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5371be73-db3f-4d79-bde7-94fcd5ea13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%define_component\n",
    "AutoMLOps.makeComponent(\n",
    "    name=\"train_model\",\n",
    "    description=\"Trains a decision tree on the training data.\",\n",
    "    params=[\n",
    "        {\"name\": \"model_directory\", \"type\": str, \"description\": \"GS location of saved model.\"},\n",
    "        {\"name\": \"data_path\", \"type\": str, \"description\": \"GS location where the training data.\"}\n",
    "    ]\n",
    ")\n",
    "# Component code goes below:\n",
    "def save_model(model, model_directory):\n",
    "    \"\"\"Saves a model to uri.\"\"\"\n",
    "    filename = f'model.pkl'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    bucket_name = model_directory.split('/')[2]\n",
    "    prefix='/'.join(model_directory.split('/')[3:])\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(os.path.join(prefix, filename))\n",
    "    blob.upload_from_filename(filename)\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "labels = df.pop(\"Class\").tolist()\n",
    "data = df.values.tolist()\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels)\n",
    "skmodel = DecisionTreeClassifier()\n",
    "skmodel.fit(x_train,y_train)\n",
    "score = skmodel.score(x_test,y_test)\n",
    "print('accuracy is:',score)\n",
    "\n",
    "output_uri = os.path.join(model_directory, f'model.pkl')\n",
    "save_model(skmodel, model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ed1eaa",
   "metadata": {},
   "source": [
    "## Uploading & Deploying the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47377d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%define_component\n",
    "AutoMLOps.makeComponent(\n",
    "    name=\"deploy_model\",\n",
    "    description=\"Trains a decision tree on the training data.\",\n",
    "    params=[\n",
    "        {\"name\": \"model_directory\", \"type\": str, \"description\": \"GS location of saved model.\"},\n",
    "        {\"name\": \"project_id\", \"type\": str, \"description\": \"Project_id.\"},\n",
    "        {\"name\": \"region\", \"type\": str, \"description\": \"Region.\"}\n",
    "    ]\n",
    ")\n",
    "# Component code goes below:\n",
    "aiplatform.init(project=project_id, location=region)\n",
    "deployed_model = aiplatform.Model.upload(\n",
    "    display_name=\"beans-model-pipeline\",\n",
    "    artifact_uri = model_directory,\n",
    "    serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\"\n",
    ")\n",
    "endpoint = deployed_model.deploy(machine_type=\"n1-standard-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d96dcb-a020-4bab-b0e3-1e32f6b2aecf",
   "metadata": {},
   "source": [
    "## Define and Run the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a36e0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoMLOps.makePipeline(\n",
    "    name=\"training-pipeline\",\n",
    "    description=\"description\", # optional\n",
    "    params=[\n",
    "        {\"name\": \"bq_table\", \"type\": str}, # descriptions are optional\n",
    "        {\"name\": \"model_directory\", \"type\": str, \"description\": \"Description.\"},\n",
    "        {\"name\": \"data_path\", \"type\": str, \"description\": \"Description.\"},\n",
    "        {\"name\": \"project_id\", \"type\": str, \"description\": \"Description.\"},\n",
    "        {\"name\": \"region\", \"type\": str, \"description\": \"Description.\"}\n",
    "    ],\n",
    "    pipeline=[{\n",
    "        \"component_name\": \"create_dataset\", \"param_mapping\": [\n",
    "            (\"bq_table\", \"bq_table\"), # (component_param, pipeline_param)\n",
    "            (\"data_path\", \"data_path\"),\n",
    "            (\"project_id\", \"project_id\")\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"component_name\": \"train_model\", \"param_mapping\": [\n",
    "            (\"model_directory\", \"model_directory\"),\n",
    "            (\"data_path\", \"data_path\")\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"component_name\": \"deploy_model\", \"param_mapping\": [\n",
    "            (\"model_directory\", \"model_directory\"),\n",
    "            (\"project_id\", \"project_id\"),\n",
    "            (\"region\", \"region\")\n",
    "        ]\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cb3786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"automlops-sandbox\"\n",
    "pipeline_params = {\n",
    "    \"bq_table\": f\"{PROJECT_ID}.test_dataset.dry-beans\",\n",
    "    \"model_directory\": f\"gs://{PROJECT_ID}-bucket/trained_models/{datetime.datetime.now()}\",\n",
    "    \"data_path\": f\"gs://{PROJECT_ID}-bucket/data\",\n",
    "    \"project_id\": f\"{PROJECT_ID}\",\n",
    "    \"region\": \"us-central1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db51a8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Successfully saved requirements file in AutoMLOps/components/component_base/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "AutoMLOps.generate(project_id=PROJECT_ID, pipeline_params=pipeline_params, use_kfp_spec=False, run_local=False, schedule_pattern='0 */12 * * *')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ef279e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Successfully saved requirements file in AutoMLOps/components/component_base/requirements.txt\n",
      "\u001b[0;32m Updating required API services in project automlops-sandbox \u001b[0m\n",
      "Operation \"operations/acat.p2-45373616427-957dc83a-db0c-47c8-8d9c-5c344058019f\" finished successfully.\n",
      "\u001b[0;32m Checking for Artifact Registry: vertex-mlops-af in project automlops-sandbox \u001b[0m\n",
      "Listing items under project automlops-sandbox, location us-central1.\n",
      "\n",
      "vertex-mlops-af  DOCKER  STANDARD_REPOSITORY  Artifact Registry vertex-mlops-af in us-central1.  us-central1          Google-managed key  2023-01-11T17:12:26  2023-01-13T12:00:34  2760.085\n",
      "Artifact Registry: vertex-mlops-af already exists in project automlops-sandbox\n",
      "\u001b[0;32m Checking for GS Bucket: automlops-sandbox-bucket in project automlops-sandbox \u001b[0m\n",
      "gs://automlops-sandbox-bucket/\n",
      "GS Bucket: automlops-sandbox-bucket already exists in project automlops-sandbox\n",
      "\u001b[0;32m Checking for Service Account: vertex-pipelines in project automlops-sandbox \u001b[0m\n",
      "Pipeline Runner Service Account         vertex-pipelines@automlops-sandbox.iam.gserviceaccount.com  False\n",
      "Service Account: vertex-pipelines already exists in project automlops-sandbox\n",
      "\u001b[0;32m Updating required IAM roles in project automlops-sandbox \u001b[0m\n",
      "\u001b[0;32m Checking for Cloud Source Repository: AutoMLOps-repo in project automlops-sandbox \u001b[0m\n",
      "AutoMLOps-repo  automlops-sandbox  https://source.developers.google.com/p/automlops-sandbox/r/AutoMLOps-repo\n",
      "Cloud Source Repository: AutoMLOps-repo already exists in project automlops-sandbox\n",
      "Cloning Cloud Source Repository: AutoMLOps-repo\n",
      "Cloning into '/Users/srastatter/Documents/2023/MLOps-graduation/AutoMLOps/example/AutoMLOps-repo'...\n",
      "warning: remote HEAD refers to nonexistent ref, unable to checkout.\n",
      "\n",
      "Project [automlops-sandbox] repository [AutoMLOps-repo] was cloned to [/Users/srastatter/Documents/2023/MLOps-graduation/AutoMLOps/example/AutoMLOps-repo].\n",
      "Switched to a new branch 'automlops'\n",
      "\u001b[0;32m Checking for Cloudbuild Trigger: automlops-trigger in project automlops-sandbox \u001b[0m\n",
      "name: automlops-trigger\n",
      "Cloudbuild Trigger already exists in project automlops-sandbox for repo AutoMLOps-repo\n",
      "[automlops 8609f82] Run AutoMLOps\n",
      " 2 files changed, 15 insertions(+), 109 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: It seems you're using Apple Git (git/2.37.1 (Apple Git-137.1),gzip(gfe),gzip(gfe)). Apple Git is not frequently updated and often has known vulnerabilities. Please follow the instructions at go/old-git-client#gmac to use a more current version of Git.        \n",
      "To https://source.developers.google.com/p/automlops-sandbox/r/AutoMLOps-repo\n",
      "   45f1b45..8609f82  automlops -> automlops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushing code to automlops branch, triggering cloudbuild...\n",
      "Waiting for cloudbuild job to complete.............Submitting PipelineJob...\n",
      "WARNING: This command is using service account impersonation. All API calls will be executed as [vertex-pipelines@automlops-sandbox.iam.gserviceaccount.com].\n",
      "\u001b[0;32m Submitting training job to Cloud Runner Service https://run-pipeline-q5owjmymra-uc.a.run.app using @pipelines/runtime_parameters/pipeline_parameter_values.json \u001b[0m\n",
      "Warning: --trace-ascii overrides an earlier trace/verbose option\n",
      "Note: Unnecessary use of -X or --request, POST is already inferred.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0== Info:   Trying 216.239.36.53:443...\n",
      "== Info: Connected to run-pipeline-q5owjmymra-uc.a.run.app (216.239.36.53) port 443 (#0)\n",
      "== Info: ALPN: offers http/1.1\n",
      "== Info:  CAfile: /etc/ssl/cert.pem\n",
      "== Info:  CApath: none\n",
      "== Info: (304) (OUT), TLS handshake, Client hello (1):\n",
      "=> Send SSL data, 338 bytes (0x152)\n",
      "0000: ...N...(. 1.w.NS.-,.v;]..ts.C...$f.... O.5=B7.M8.t.+......4.).%$\n",
      "0040: 5..../ .b.............0.,.(.$.......k.9...........=.5...../.+.'.\n",
      "0080: #.......g.3...E...<./...A.......................+............3.&\n",
      "00c0: .$... ....@..%..../..6....p--......(F....).'..$run-pipeline-q5ow\n",
      "0100: jmymra-uc.a.run.app.............................................\n",
      "0140: ..........http/1.1\n",
      "== Info: (304) (IN), TLS handshake, Server hello (2):\n",
      "<= Recv SSL data, 122 bytes (0x7a)\n",
      "0000: ...v..FV._..........!gvf..OH..phUz...A O.5=B7.M8.t.+......4.).%$\n",
      "0040: 5..../ ......3.$... ...tw...f-..........toB....6.Q...+....\n",
      "== Info: (304) (IN), TLS handshake, Unknown (8):\n",
      "<= Recv SSL data, 21 bytes (0x15)\n",
      "0000: .............http/1.1\n",
      "== Info: (304) (IN), TLS handshake, Certificate (11):\n",
      "<= Recv SSL data, 4005 bytes (0xfa5)\n",
      "0000: ...........0...0..r.......?*.p......D.....0...*.H........0F1.0..\n",
      "0040: .U....US1\"0 ..U....Google Trust Services LLC1.0...U....GTS CA 1C\n",
      "0080: 30...221128081545Z..230220081544Z0.1.0...U....*.a.run.app0Y0...*\n",
      "00c0: .H.=....*.H.=....B......I....^...k.^R....8...\\..../Y.....n...0.}\n",
      "0100: .3l(.....<..^E...e.....m0..i0...U...........0...U.%..0...+......\n",
      "0140: .0...U.......0.0...U............g..^m...%rm...0...U.#..0....t...\n",
      "0180: ....=...F..q5.'0j..+........^0\\0'..+.....0...http://ocsp.pki.goo\n",
      "01c0: g/gts1c301..+.....0..%http://pki.goog/repo/certs/gts1c3.der0...U\n",
      "0200: ....0...*.a.run.app..run.app0!..U. ..0.0...g.....0...+.....y...0\n",
      "0240: <..U...50301./.-.+http://crls.pki.goog/gts1c3/zdATt0Ex_Fk.crl0..\n",
      "0280: ...+.....y............v.....|.....=..>.j.g)]...$...4............\n",
      "02c0: .....G0E. S.....:;u.......`Atj.h..Rb*...B..!...r......B?.o..3..G\n",
      "0300: .......Z..t...v..sw...P.c.......Jy-.g.......y6...............G0E\n",
      "0340: .!..r......-.A_(..qV..?..[..l..BHk.. ........E........$..$.B?...\n",
      "0380: ..*..0...*.H...............[=o..3...........*X...54%i.N........b\n",
      "03c0: N..........(..q..b.N....-..8........9..E?}......`.6....m2,...<..\n",
      "0400: ....]....[..0..._P{1PoAx........lG7..........]/...,:.[....*).)s.\n",
      "0440: .s.:...G.\\.YJ.X5F...?X?.#I.UM.kE .Z6O...(n....\"........3.Va..o..\n",
      "0480: .~.E|..RKz@.@..\"..M*js..s.....0...0..~..........SYk4....Pf0...*.\n",
      "04c0: H........0G1.0...U....US1\"0 ..U....Google Trust Services LLC1.0.\n",
      "0500: ..U....GTS Root R10...200813000042Z..270930000042Z0F1.0...U....U\n",
      "0540: S1\"0 ..U....Google Trust Services LLC1.0...U....GTS CA 1C30..\"0.\n",
      "0580: ..*.H.............0............b..7.7B..l...e.%...k..m.Z#.......\n",
      "05c0: ..|....B.^V$.z3....i..t.WLfh.w7US.9.M.4._%w7;...<......C...G..D.\n",
      "0600: c..A..A0H......E.!..B...+eV4.&....}....H|7M?.....u..yW\\.Wn......\n",
      "0640: ...%...,...*....c.<PI...._.+Y.....Q..w....O.pI.\\m .......w.-...k\n",
      "0680: ....+........'....Q.................0..|0...U...........0...U.%.\n",
      "06c0: .0...+.........+.......0...U.......0.......0...U.......t.......=\n",
      "0700: ...F..q5.'0...U.#..0.....+&q.+H'./Rf,....q>0h..+........\\0Z0&..+\n",
      "0740: .....0...http://ocsp.pki.goog/gtsr100..+.....0..$http://pki.goog\n",
      "0780: /repo/certs/gtsr1.der04..U...-0+0).'.%.#http://crl.pki.goog/gtsr\n",
      "07c0: 1/gtsr1.crl0W..U. .P0N08..+.....y...0*0(..+.........https://pki.\n",
      "0800: goog/repository/0...g.....0...g.....0...*.H..............}. \\.<.\n",
      "0840: ..W.......rq.6...@..L.F...$..Pq\"...n...jo......_.l.......b....[.\n",
      "0880: f.........i>z.FI_F.A...Me4...?O.l.I..SA..!.....D[*P..M.S6.B..T..\n",
      "08c0: wS.d8'...X..|9-[..........S$....y.&.a.SR.B..f+?...........q.5($.\n",
      "0900: ....-.H.=Y.Q.t..|...[..4...........\"....q....s$.7S...?..\\.6..;.)\n",
      "0940: ...:b;lc...Yq.c'.L....s..*....l2.3...Qq.4...].QX......Y.q..M(..m\n",
      "0980: ......F...k.w.....#.........D..u#.4.. ..^...RF.....!pQ.....U.+.3\n",
      "09c0: w.KB..w..s.....7?..*f.s.2.2l2....#.[}Mep.+.=...m.2.....c...]...q\n",
      "0a00: ^*...\"..e:...e.....[.Y.G.-.$:...&....7..o....Q.......Q......f0..\n",
      "0a40: b0..J.......w..l.6...!...X..0...*.H........0W1.0...U....BE1.0...\n",
      "0a80: U....GlobalSign nv-sa1.0...U....Root CA1.0...U....GlobalSign Roo\n",
      "0ac0: t CA0...200619000042Z..280128000042Z0G1.0...U....US1\"0 ..U....Go\n",
      "0b00: ogle Trust Services LLC1.0...U....GTS Root R10..\"0...*.H........\n",
      "0b40: .....0...............w.;...>...@<....}2..q........j.....K.+.....\n",
      "0b80: ..............^..R..#'....c...~..^.h...ZG.M.3.N.....lK......d)%#\n",
      "0bc0: ....=.`.......H.M..z.....Y........1.......ml....~&.E.=.y..(...&.\n",
      "0c00: .....<h.S..:.+.....z..u....Vd..Oh.=......@..\\....5l..P...L... .3\n",
      "0c40: .R..2.).%*.H.r..d...........8f..c...x.{\\w.v......y.W..&.........\n",
      "0c80: .....U.....K)...2%N*.eD.....I...|..@{.C..l..}...L......K.....E.v\n",
      "0cc0: ..@+.S....;......1..w.o{>...\".....2..c.Qr.]....)h3.:f...&...Wex'\n",
      "0d00: .^I.......!............lH<@.~.Z.V<.....K.9K..?.U.n$..q..........\n",
      "0d40: A...=:..z.7...........80..40...U...........0...U.......0....0...\n",
      "0d80: U........+&q.+H'./Rf,....q>0...U.#..0...`{f.E....P/}..4....K0`..\n",
      "0dc0: +........T0R0%..+.....0...http://ocsp.pki.goog/gsr10)..+.....0..\n",
      "0e00: .http://pki.goog/gsr1/gsr1.crt02..U...+0)0'.%.#.!http://crl.pki.\n",
      "0e40: goog/gsr1/gsr1.crl0;..U. .4020...g.....0...g.....0...+.....y....\n",
      "0e80: 0...+.....y....0...*.H.............4...(...v..1z!..R>..t.A..=5..\n",
      "0ec0: ....\\_...|......W.&o[..Fh.7okz...7.%Q..h...I.Z...#...+.....Ij.u.\n",
      "0f00: ......XHW.5.....o..o.......*..Ni..-.h..+s....\".7..f.I..U.g.2..&.\n",
      "0f40: p.=.gm=|.4..2..n.jo.....K.;..7..D.~.l..F.....!.f...Ul.)...f[.wIH\n",
      "0f80: (....3rS..5.b..$...9..~*A.R.......?..\n",
      "== Info: (304) (IN), TLS handshake, CERT verify (15):\n",
      "<= Recv SSL data, 78 bytes (0x4e)\n",
      "0000: ...J...F0D. e.....3....Y.. .! ..Qu.S..}7...F. X...l.Z9...\\.m.p..\n",
      "0040: D.........WHG.\n",
      "== Info: (304) (IN), TLS handshake, Finished (20):\n",
      "<= Recv SSL data, 36 bytes (0x24)\n",
      "0000: ... s.]$.-...=....\"......Y.._.}.T..s\n",
      "== Info: (304) (OUT), TLS handshake, Finished (20):\n",
      "=> Send SSL data, 36 bytes (0x24)\n",
      "0000: ... k.u$...>'\".e.d...G)%....R......h\n",
      "== Info: SSL connection using TLSv1.3 / AEAD-CHACHA20-POLY1305-SHA256\n",
      "== Info: ALPN: server accepted http/1.1\n",
      "== Info: Server certificate:\n",
      "== Info:  subject: CN=*.a.run.app\n",
      "== Info:  start date: Nov 28 08:15:45 2022 GMT\n",
      "== Info:  expire date: Feb 20 08:15:44 2023 GMT\n",
      "== Info:  subjectAltName: host \"run-pipeline-q5owjmymra-uc.a.run.app\" matched cert's \"*.a.run.app\"\n",
      "== Info:  issuer: C=US; O=Google Trust Services LLC; CN=GTS CA 1C3\n",
      "== Info:  SSL certificate verify ok.\n",
      "=> Send header, 869 bytes (0x365)\n",
      "0000: POST / HTTP/1.1\n",
      "0011: Host: run-pipeline-q5owjmymra-uc.a.run.app\n",
      "003d: User-Agent: curl/7.85.0\n",
      "0056: Accept: */*\n",
      "0063: Authorization:bearer eyJhbGciOiJSUzI1NiIsImtpZCI6ImEyOWFiYzE5YmU\n",
      "00a3: yN2ZiNDE1MWFhNDMxZTk0ZmEzNjgwYWU0NThkYTUiLCJ0eXAiOiJKV1QifQ.eyJh\n",
      "00e3: dWQiOiJodHRwczovL3J1bi1waXBlbGluZS1xNW93am15bXJhLXVjLmEucnVuLmFw\n",
      "0123: cCIsImF6cCI6IjEwMDQ4MDUwMjkzMDQyNDQ4NTM0NCIsImV4cCI6MTY3MzYzMzE0\n",
      "0163: MiwiaWF0IjoxNjczNjI5NTQyLCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2ds\n",
      "01a3: ZS5jb20iLCJzdWIiOiIxMDA0ODA1MDI5MzA0MjQ0ODUzNDQifQ.ESN8By70LdyRb\n",
      "01e3: _AGc4LyucrXgyyWHKf4tmzTg1IFF1NGxTRzELNHz0M8FRCzvb2VP1xVTULo0kw1O\n",
      "0223: -qgtThuvQc0926pq7gs4Fk_p-zLqQgHFIbbRkLXmoofs8Rpd4UehUOh367zj7Yg2\n",
      "0263: 9NUZt6vk2mGaYBUPQKDEMXaDqRJik6rtr4l7PTh5p3ak4Efnh-8WP1fp-0d6nP-m\n",
      "02a3: UCIUSSX28CGwgljm5gCV8-2es2TPznKan6SmPobvq7f6GBPZ8Gvjkeb5NeJt7bSJ\n",
      "02e3: fxSOG7URotsb5ZbJtHmqeteLrJKjva3jmIAP-27YzFbn9ouiY9cNiYTq72m2WMd6\n",
      "0323: _NgxFLW1Q\n",
      "032e: Content-Type: application/json\n",
      "034e: Content-Length: 277\n",
      "0363: \n",
      "=> Send data, 277 bytes (0x115)\n",
      "0000: {    \"bq_table\": \"automlops-sandbox.test_dataset.dry-beans\",    \n",
      "0040: \"model_directory\": \"gs://automlops-sandbox-bucket/trained_models\n",
      "0080: /2023-01-13 12:01:49.097766\",    \"data_path\": \"gs://automlops-sa\n",
      "00c0: ndbox-bucket/data\",    \"project_id\": \"automlops-sandbox\",    \"re\n",
      "0100: gion\": \"us-central1\"}\n",
      "100   277    0     0  100   277      0     52  0:00:05  0:00:05 --:--:--    52== Info: Mark bundle as not supporting multiuse\n",
      "<= Recv header, 17 bytes (0x11)\n",
      "0000: HTTP/1.1 200 OK\n",
      "<= Recv header, 32 bytes (0x20)\n",
      "0000: content-type: application/json\n",
      "<= Recv header, 61 bytes (0x3d)\n",
      "0000: X-Cloud-Trace-Context: 809209e4c95776273e8bf526c74f17d9;o=1\n",
      "<= Recv header, 37 bytes (0x25)\n",
      "0000: Date: Fri, 13 Jan 2023 17:05:47 GMT\n",
      "<= Recv header, 25 bytes (0x19)\n",
      "0000: Server: Google Frontend\n",
      "<= Recv header, 21 bytes (0x15)\n",
      "0000: Content-Length: 260\n",
      "<= Recv header, 173 bytes (0xad)\n",
      "0000: Alt-Svc: h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000,h3-Q050=\n",
      "0040: \":443\"; ma=2592000,h3-Q046=\":443\"; ma=2592000,h3-Q043=\":443\"; ma\n",
      "0080: =2592000,quic=\":443\"; ma=2592000; v=\"46,43\"\n",
      "<= Recv header, 2 bytes (0x2)\n",
      "0000: \n",
      "<= Recv data, 260 bytes (0x104)\n",
      "0000: {\"dashboard_uri\":\"https://console.cloud.google.com/vertex-ai/loc\n",
      "0040: ations/us-central1/pipelines/runs/training-pipeline-202301131705\n",
      "0080: 47?project=45373616427\",\"resource_name\":\"projects/45373616427/lo\n",
      "00c0: cations/us-central1/pipelineJobs/training-pipeline-2023011317054\n",
      "0100: 7\"}.\n",
      "100   537  100   260  100   277     45     48  0:00:05  0:00:05 --:--:--    73\n",
      "{\"dashboard_uri\":\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/training-pipeline-20230113170547?project=45373616427\",\"resource_name\":\"projects/45373616427/locations/us-central1/pipelineJobs/training-pipeline-20230113170547\"}\n",
      "== Info: Connection #0 to host run-pipeline-q5owjmymra-uc.a.run.app left intact\n",
      "Creating Cloud Scheduler Job\n",
      "\u001b[0;32m Checking for Cloud Scheduler Job: AutoMLOps-schedule in project automlops-sandbox \u001b[0m\n",
      "AutoMLOps-schedule  us-central1  0 */12 * * * (Etc/UTC)  HTTP         ENABLED\n",
      "Cloud Scheduler AutoMLOps resource already exists in project automlops-sandbox or Cloud Runner service not found\n",
      "\n",
      "#################################################################\n",
      "#                                                               #\n",
      "#                       RESOURCES MANIFEST                      #\n",
      "#---------------------------------------------------------------#\n",
      "#     Generated resources can be found at the following urls    #\n",
      "#                                                               #\n",
      "#################################################################\n",
      "\n",
      "Google Cloud Storage Bucket: https://console.cloud.google.com/storage/automlops-sandbox-bucket\n",
      "Artifact Registry: https://console.cloud.google.com/artifacts/docker/automlops-sandbox/us-central1/vertex-mlops-af\n",
      "Service Accounts: https://console.cloud.google.com/iam-admin/serviceaccounts?project=automlops-sandbox\n",
      "APIs: https://console.cloud.google.com/apis\n",
      "Cloud Source Repository: https://source.cloud.google.com/automlops-sandbox/AutoMLOps-repo/+/automlops:\n",
      "Cloud Build Jobs: https://console.cloud.google.com/cloud-build/builds\n",
      "Vertex AI Pipeline Runs: https://console.cloud.google.com/vertex-ai/pipelines/runs\n",
      "Cloud Build Trigger: https://console.cloud.google.com/cloud-build/triggers;region=us-central1\n",
      "Cloud Run Service: https://console.cloud.google.com/run/detail/us-central1/run-pipeline\n",
      "Cloud Scheduler Job: https://console.cloud.google.com/cloudscheduler\n"
     ]
    }
   ],
   "source": [
    "# .go() calls .generate() and runs the code\n",
    "AutoMLOps.go(project_id=PROJECT_ID, pipeline_params=pipeline_params, use_kfp_spec=False, run_local=False, schedule_pattern='0 */12 * * *')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccca3907",
   "metadata": {},
   "source": [
    "## Default Run Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c92f80a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Successfully saved requirements file in AutoMLOps/components/component_base/requirements.txt\n",
      "\u001b[0;32m Updating required API services in project automlops-sandbox \u001b[0m\n",
      "Operation \"operations/acat.p2-45373616427-f7b2644e-1b69-4faf-b983-42e5e0c4202c\" finished successfully.\n",
      "\u001b[0;32m Checking for Artifact Registry: vertex-mlops-af in project automlops-sandbox \u001b[0m\n",
      "Listing items under project automlops-sandbox, location us-central1.\n",
      "\n",
      "vertex-mlops-af  DOCKER  STANDARD_REPOSITORY  Artifact Registry vertex-mlops-af in us-central1.  us-central1          Google-managed key  2023-01-11T17:12:26  2023-01-13T12:05:31  2951.969\n",
      "Artifact Registry: vertex-mlops-af already exists in project automlops-sandbox\n",
      "\u001b[0;32m Checking for GS Bucket: automlops-sandbox-bucket in project automlops-sandbox \u001b[0m\n",
      "gs://automlops-sandbox-bucket/\n",
      "GS Bucket: automlops-sandbox-bucket already exists in project automlops-sandbox\n",
      "\u001b[0;32m Checking for Service Account: vertex-pipelines in project automlops-sandbox \u001b[0m\n",
      "Pipeline Runner Service Account         vertex-pipelines@automlops-sandbox.iam.gserviceaccount.com  False\n",
      "Service Account: vertex-pipelines already exists in project automlops-sandbox\n",
      "\u001b[0;32m Updating required IAM roles in project automlops-sandbox \u001b[0m\n",
      "\u001b[0;32m Checking for Cloud Source Repository: AutoMLOps-repo in project automlops-sandbox \u001b[0m\n",
      "AutoMLOps-repo  automlops-sandbox  https://source.developers.google.com/p/automlops-sandbox/r/AutoMLOps-repo\n",
      "Cloud Source Repository: AutoMLOps-repo already exists in project automlops-sandbox\n",
      "Cloning Cloud Source Repository: AutoMLOps-repo\n",
      "Cloning into '/Users/srastatter/Documents/2023/MLOps-graduation/AutoMLOps/example/AutoMLOps-repo'...\n",
      "warning: remote HEAD refers to nonexistent ref, unable to checkout.\n",
      "\n",
      "Project [automlops-sandbox] repository [AutoMLOps-repo] was cloned to [/Users/srastatter/Documents/2023/MLOps-graduation/AutoMLOps/example/AutoMLOps-repo].\n",
      "Switched to a new branch 'automlops'\n",
      "\u001b[0;32m BUILDING COMPONENTS \u001b[0m\n",
      "Creating temporary tarball archive of 33 file(s) totalling 2.7 MiB before compression.\n",
      "Uploading tarball of [..] to [gs://automlops-sandbox_cloudbuild/source/1673629859.273013-a15a0cc014094258bdce17822fa8042e.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/automlops-sandbox/locations/global/builds/3c6aef3b-8dff-4ad4-998c-4abf402a6862].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/3c6aef3b-8dff-4ad4-998c-4abf402a6862?project=45373616427 ].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"3c6aef3b-8dff-4ad4-998c-4abf402a6862\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://automlops-sandbox_cloudbuild/source/1673629859.273013-a15a0cc014094258bdce17822fa8042e.tgz#1673629861884604\n",
      "Copying gs://automlops-sandbox_cloudbuild/source/1673629859.273013-a15a0cc014094258bdce17822fa8042e.tgz#1673629861884604...\n",
      "/ [1 files][  1.1 MiB/  1.1 MiB]                                                \n",
      "Operation completed over 1 objects/1.1 MiB.\n",
      "BUILD\n",
      "Starting Step #0 - \"build_component_base\"\n",
      "Step #0 - \"build_component_base\": Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #0 - \"build_component_base\": Sending build context to Docker daemon  13.82kB\n",
      "Step #0 - \"build_component_base\": Step 1/6 : FROM python:3.9\n",
      "Step #0 - \"build_component_base\": 3.9: Pulling from library/python\n",
      "Step #0 - \"build_component_base\": bbeef03cda1f: Pulling fs layer\n",
      "Step #0 - \"build_component_base\": f049f75f014e: Pulling fs layer\n",
      "Step #0 - \"build_component_base\": 56261d0e6b05: Pulling fs layer\n",
      "Step #0 - \"build_component_base\": 9bd150679dbd: Pulling fs layer\n",
      "Step #0 - \"build_component_base\": 5b282ee9da04: Pulling fs layer\n",
      "Step #0 - \"build_component_base\": 03f027d5e312: Pulling fs layer\n",
      "Step #0 - \"build_component_base\": 286b1eb89681: Pulling fs layer\n",
      "Step #0 - \"build_component_base\": ac2f1c18cd99: Pulling fs layer\n",
      "Step #0 - \"build_component_base\": a9498bae351f: Pulling fs layer\n",
      "Step #0 - \"build_component_base\": 9bd150679dbd: Waiting\n",
      "Step #0 - \"build_component_base\": 5b282ee9da04: Waiting\n",
      "Step #0 - \"build_component_base\": 03f027d5e312: Waiting\n",
      "Step #0 - \"build_component_base\": 286b1eb89681: Waiting\n",
      "Step #0 - \"build_component_base\": ac2f1c18cd99: Waiting\n",
      "Step #0 - \"build_component_base\": a9498bae351f: Waiting\n",
      "Step #0 - \"build_component_base\": f049f75f014e: Verifying Checksum\n",
      "Step #0 - \"build_component_base\": f049f75f014e: Download complete\n",
      "Step #0 - \"build_component_base\": 56261d0e6b05: Verifying Checksum\n",
      "Step #0 - \"build_component_base\": 56261d0e6b05: Download complete\n",
      "Step #0 - \"build_component_base\": bbeef03cda1f: Verifying Checksum\n",
      "Step #0 - \"build_component_base\": bbeef03cda1f: Download complete\n",
      "Step #0 - \"build_component_base\": 9bd150679dbd: Verifying Checksum\n",
      "Step #0 - \"build_component_base\": 9bd150679dbd: Download complete\n",
      "Step #0 - \"build_component_base\": 03f027d5e312: Verifying Checksum\n",
      "Step #0 - \"build_component_base\": 03f027d5e312: Download complete\n",
      "Step #0 - \"build_component_base\": ac2f1c18cd99: Verifying Checksum\n",
      "Step #0 - \"build_component_base\": ac2f1c18cd99: Download complete\n",
      "Step #0 - \"build_component_base\": a9498bae351f: Verifying Checksum\n",
      "Step #0 - \"build_component_base\": a9498bae351f: Download complete\n",
      "Step #0 - \"build_component_base\": 286b1eb89681: Verifying Checksum\n",
      "Step #0 - \"build_component_base\": 286b1eb89681: Download complete\n",
      "Step #0 - \"build_component_base\": 5b282ee9da04: Verifying Checksum\n",
      "Step #0 - \"build_component_base\": 5b282ee9da04: Download complete\n",
      "Step #0 - \"build_component_base\": bbeef03cda1f: Pull complete\n",
      "Step #0 - \"build_component_base\": f049f75f014e: Pull complete\n",
      "Step #0 - \"build_component_base\": 56261d0e6b05: Pull complete\n",
      "Step #0 - \"build_component_base\": 9bd150679dbd: Pull complete\n",
      "Step #0 - \"build_component_base\": 5b282ee9da04: Pull complete\n",
      "Step #0 - \"build_component_base\": 03f027d5e312: Pull complete\n",
      "Step #0 - \"build_component_base\": 286b1eb89681: Pull complete\n",
      "Step #0 - \"build_component_base\": ac2f1c18cd99: Pull complete\n",
      "Step #0 - \"build_component_base\": a9498bae351f: Pull complete\n",
      "Step #0 - \"build_component_base\": Digest: sha256:bf508488fa1a287313bba9e4969318b1b00cf4921055dcf10996a096c28afd67\n",
      "Step #0 - \"build_component_base\": Status: Downloaded newer image for python:3.9\n",
      "Step #0 - \"build_component_base\":  ---> 8f1c967991c4\n",
      "Step #0 - \"build_component_base\": Step 2/6 : RUN python -m pip install --upgrade pip\n",
      "Step #0 - \"build_component_base\":  ---> Running in 9b5ba1ce7bc0\n",
      "Step #0 - \"build_component_base\": Requirement already satisfied: pip in /usr/local/lib/python3.9/site-packages (22.0.4)\n",
      "Step #0 - \"build_component_base\": Collecting pip\n",
      "Step #0 - \"build_component_base\":   Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
      "Step #0 - \"build_component_base\":      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 30.9 MB/s eta 0:00:00\n",
      "Step #0 - \"build_component_base\": Installing collected packages: pip\n",
      "Step #0 - \"build_component_base\":   Attempting uninstall: pip\n",
      "Step #0 - \"build_component_base\":     Found existing installation: pip 22.0.4\n",
      "Step #0 - \"build_component_base\":     Uninstalling pip-22.0.4:\n",
      "Step #0 - \"build_component_base\":       Successfully uninstalled pip-22.0.4\n",
      "Step #0 - \"build_component_base\": \u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "Step #0 - \"build_component_base\": \u001b[0mSuccessfully installed pip-22.3.1\n",
      "Step #0 - \"build_component_base\": Removing intermediate container 9b5ba1ce7bc0\n",
      "Step #0 - \"build_component_base\":  ---> a2f2bc0ad1b8\n",
      "Step #0 - \"build_component_base\": Step 3/6 : COPY requirements.txt .\n",
      "Step #0 - \"build_component_base\":  ---> eb6668a47602\n",
      "Step #0 - \"build_component_base\": Step 4/6 : RUN python -m pip install -r     requirements.txt --quiet --no-cache-dir     && rm -f requirements.txt\n",
      "Step #0 - \"build_component_base\":  ---> Running in 066b93629c96\n",
      "Step #0 - \"build_component_base\": \u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "Step #0 - \"build_component_base\": \u001b[0mRemoving intermediate container 066b93629c96\n",
      "Step #0 - \"build_component_base\":  ---> ddf803519ddb\n",
      "Step #0 - \"build_component_base\": Step 5/6 : COPY ./src /pipelines/component/src\n",
      "Step #0 - \"build_component_base\":  ---> 214316723844\n",
      "Step #0 - \"build_component_base\": Step 6/6 : ENTRYPOINT [\"/bin/bash\"]\n",
      "Step #0 - \"build_component_base\":  ---> Running in 741a3cd20675\n",
      "Step #0 - \"build_component_base\": Removing intermediate container 741a3cd20675\n",
      "Step #0 - \"build_component_base\":  ---> 16bec7876038\n",
      "Step #0 - \"build_component_base\": Successfully built 16bec7876038\n",
      "Step #0 - \"build_component_base\": Successfully tagged us-central1-docker.pkg.dev/automlops-sandbox/vertex-mlops-af/components/component_base:latest\n",
      "Finished Step #0 - \"build_component_base\"\n",
      "Starting Step #1 - \"push_component_base\"\n",
      "Step #1 - \"push_component_base\": Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #1 - \"push_component_base\": The push refers to repository [us-central1-docker.pkg.dev/automlops-sandbox/vertex-mlops-af/components/component_base]\n",
      "Step #1 - \"push_component_base\": 69ab21e3f984: Preparing\n",
      "Step #1 - \"push_component_base\": b759b479ef80: Preparing\n",
      "Step #1 - \"push_component_base\": 7d1f488f26c9: Preparing\n",
      "Step #1 - \"push_component_base\": 9fe0c0cda22c: Preparing\n",
      "Step #1 - \"push_component_base\": 315572e6ad81: Preparing\n",
      "Step #1 - \"push_component_base\": 44dda8402940: Preparing\n",
      "Step #1 - \"push_component_base\": 25972ffba58c: Preparing\n",
      "Step #1 - \"push_component_base\": dc6462f7bb8b: Preparing\n",
      "Step #1 - \"push_component_base\": a4db1a405763: Preparing\n",
      "Step #1 - \"push_component_base\": 9f4f964da727: Preparing\n",
      "Step #1 - \"push_component_base\": 49b333f7bad4: Preparing\n",
      "Step #1 - \"push_component_base\": a463dbda4664: Preparing\n",
      "Step #1 - \"push_component_base\": a9099c3159f5: Preparing\n",
      "Step #1 - \"push_component_base\": 44dda8402940: Waiting\n",
      "Step #1 - \"push_component_base\": 25972ffba58c: Waiting\n",
      "Step #1 - \"push_component_base\": dc6462f7bb8b: Waiting\n",
      "Step #1 - \"push_component_base\": a4db1a405763: Waiting\n",
      "Step #1 - \"push_component_base\": 9f4f964da727: Waiting\n",
      "Step #1 - \"push_component_base\": 49b333f7bad4: Waiting\n",
      "Step #1 - \"push_component_base\": a463dbda4664: Waiting\n",
      "Step #1 - \"push_component_base\": a9099c3159f5: Waiting\n",
      "Step #1 - \"push_component_base\": 315572e6ad81: Layer already exists\n",
      "Step #1 - \"push_component_base\": 44dda8402940: Layer already exists\n",
      "Step #1 - \"push_component_base\": 25972ffba58c: Layer already exists\n",
      "Step #1 - \"push_component_base\": dc6462f7bb8b: Layer already exists\n",
      "Step #1 - \"push_component_base\": 69ab21e3f984: Pushed\n",
      "Step #1 - \"push_component_base\": 7d1f488f26c9: Pushed\n",
      "Step #1 - \"push_component_base\": a4db1a405763: Layer already exists\n",
      "Step #1 - \"push_component_base\": 9f4f964da727: Layer already exists\n",
      "Step #1 - \"push_component_base\": 49b333f7bad4: Layer already exists\n",
      "Step #1 - \"push_component_base\": a463dbda4664: Layer already exists\n",
      "Step #1 - \"push_component_base\": a9099c3159f5: Layer already exists\n",
      "Step #1 - \"push_component_base\": 9fe0c0cda22c: Pushed\n",
      "Step #1 - \"push_component_base\": b759b479ef80: Pushed\n",
      "Step #1 - \"push_component_base\": latest: digest: sha256:67d76694b3741943d4fbed053bae7af8617e5756c02dcc6b23157337dce6ecbb size: 3057\n",
      "Finished Step #1 - \"push_component_base\"\n",
      "PUSH\n",
      "Pushing us-central1-docker.pkg.dev/automlops-sandbox/vertex-mlops-af/components/component_base:latest\n",
      "The push refers to repository [us-central1-docker.pkg.dev/automlops-sandbox/vertex-mlops-af/components/component_base]\n",
      "69ab21e3f984: Preparing\n",
      "b759b479ef80: Preparing\n",
      "7d1f488f26c9: Preparing\n",
      "9fe0c0cda22c: Preparing\n",
      "315572e6ad81: Preparing\n",
      "44dda8402940: Preparing\n",
      "25972ffba58c: Preparing\n",
      "dc6462f7bb8b: Preparing\n",
      "a4db1a405763: Preparing\n",
      "9f4f964da727: Preparing\n",
      "49b333f7bad4: Preparing\n",
      "a463dbda4664: Preparing\n",
      "a9099c3159f5: Preparing\n",
      "44dda8402940: Waiting\n",
      "25972ffba58c: Waiting\n",
      "dc6462f7bb8b: Waiting\n",
      "a4db1a405763: Waiting\n",
      "9f4f964da727: Waiting\n",
      "49b333f7bad4: Waiting\n",
      "a463dbda4664: Waiting\n",
      "a9099c3159f5: Waiting\n",
      "315572e6ad81: Layer already exists\n",
      "69ab21e3f984: Layer already exists\n",
      "7d1f488f26c9: Layer already exists\n",
      "b759b479ef80: Layer already exists\n",
      "9fe0c0cda22c: Layer already exists\n",
      "44dda8402940: Layer already exists\n",
      "9f4f964da727: Layer already exists\n",
      "dc6462f7bb8b: Layer already exists\n",
      "49b333f7bad4: Layer already exists\n",
      "a9099c3159f5: Layer already exists\n",
      "25972ffba58c: Layer already exists\n",
      "a4db1a405763: Layer already exists\n",
      "a463dbda4664: Layer already exists\n",
      "latest: digest: sha256:67d76694b3741943d4fbed053bae7af8617e5756c02dcc6b23157337dce6ecbb size: 3057\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                           IMAGES                                                                                            STATUS\n",
      "3c6aef3b-8dff-4ad4-998c-4abf402a6862  2023-01-13T17:11:02+00:00  2M30S     gs://automlops-sandbox_cloudbuild/source/1673629859.273013-a15a0cc014094258bdce17822fa8042e.tgz  us-central1-docker.pkg.dev/automlops-sandbox/vertex-mlops-af/components/component_base (+1 more)  SUCCESS\n",
      "\u001b[0;32m BUILDING PIPELINE SPEC \u001b[0m\n",
      "/Users/srastatter/Library/Python/3.9/lib/python/site-packages/kfp/v2/compiler/compiler.py:1290: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  warnings.warn(\n",
      "\u001b[0;32m RUNNING PIPELINE JOB \u001b[0m\n",
      "Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/45373616427/locations/us-central1/pipelineJobs/training-pipeline-20230113121338\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/45373616427/locations/us-central1/pipelineJobs/training-pipeline-20230113121338\n",
      "To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/45373616427/locations/us-central1/pipelineJobs/training-pipeline-20230113121338')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/45373616427/locations/us-central1/pipelineJobs/training-pipeline-20230113121338')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/training-pipeline-20230113121338?project=45373616427\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/training-pipeline-20230113121338?project=45373616427\n",
      "\n",
      "#################################################################\n",
      "#                                                               #\n",
      "#                       RESOURCES MANIFEST                      #\n",
      "#---------------------------------------------------------------#\n",
      "#     Generated resources can be found at the following urls    #\n",
      "#                                                               #\n",
      "#################################################################\n",
      "\n",
      "Google Cloud Storage Bucket: https://console.cloud.google.com/storage/automlops-sandbox-bucket\n",
      "Artifact Registry: https://console.cloud.google.com/artifacts/docker/automlops-sandbox/us-central1/vertex-mlops-af\n",
      "Service Accounts: https://console.cloud.google.com/iam-admin/serviceaccounts?project=automlops-sandbox\n",
      "APIs: https://console.cloud.google.com/apis\n",
      "Cloud Source Repository: https://source.cloud.google.com/automlops-sandbox/AutoMLOps-repo/+/automlops:\n",
      "Cloud Build Jobs: https://console.cloud.google.com/cloud-build/builds\n",
      "Vertex AI Pipeline Runs: https://console.cloud.google.com/vertex-ai/pipelines/runs\n"
     ]
    }
   ],
   "source": [
    "AutoMLOps.go(project_id=PROJECT_ID, # required\n",
    "             pipeline_params=pipeline_params, # required\n",
    "             af_registry_location='us-central1', # default\n",
    "             af_registry_name='vertex-mlops-af', # default\n",
    "             cb_trigger_location='us-central1', # default\n",
    "             cb_trigger_name='automlops-trigger', # default\n",
    "             cloud_run_location='us-central1', # default\n",
    "             cloud_run_name='run-pipeline', # default\n",
    "             csr_branch_name='automlops', # default\n",
    "             csr_name='AutoMLOps-repo', # default\n",
    "             gs_bucket_location='us-central1', # default\n",
    "             gs_bucket_name=None, # default\n",
    "             parameter_values_path='pipelines/runtime_parameters/pipeline_parameter_values.json', # default\n",
    "             pipeline_job_spec_path='scripts/pipeline_spec/pipeline_job.json', # default\n",
    "             pipeline_runner_sa=None, # default\n",
    "             run_local=True, # default\n",
    "             schedule_location='us-central1', # default\n",
    "             schedule_name='AutoMLOps-schedule', # default\n",
    "             schedule_pattern='No Schedule Specified', # default\n",
    "             use_kfp_spec=False # default\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715a8a22",
   "metadata": {},
   "source": [
    "## 2. Using KFP Spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0856cbc0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36329f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from kfp.v2 import compiler, dsl\n",
    "from kfp.v2.dsl import pipeline, component, Artifact, Dataset, Input, Metrics, Model, Output, InputPath, OutputPath\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1\n",
    "import datetime\n",
    "\n",
    "from AutoMLOps import AutoMLOps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb34204",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89b82a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\n",
    "        \"google-cloud-bigquery\", \n",
    "        \"pandas\",\n",
    "        \"pyarrow\",\n",
    "        \"db_dtypes\"\n",
    "    ],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=f\"{AutoMLOps.OUTPUT_DIR}/create_dataset.yaml\"\n",
    ")\n",
    "def create_dataset(\n",
    "    bq_table: str,\n",
    "    output_data_path: OutputPath(\"Dataset\"),\n",
    "    project: str\n",
    "):\n",
    "    from google.cloud import bigquery\n",
    "    import pandas as pd\n",
    "    bq_client = bigquery.Client(project=project)\n",
    "\n",
    "\n",
    "    def get_query(bq_input_table: str) -> str:\n",
    "        \"\"\"Generates BQ Query to read data.\n",
    "\n",
    "        Args:\n",
    "        bq_input_table: The full name of the bq input table to be read into\n",
    "        the dataframe (e.g. <project>.<dataset>.<table>)\n",
    "        Returns: A BQ query string.\n",
    "        \"\"\"\n",
    "        return f\"\"\"\n",
    "        SELECT *\n",
    "        FROM `{bq_input_table}`\n",
    "        \"\"\"\n",
    "\n",
    "    def load_bq_data(query: str, client: bigquery.Client) -> pd.DataFrame:\n",
    "        \"\"\"Loads data from bq into a Pandas Dataframe for EDA.\n",
    "        Args:\n",
    "        query: BQ Query to generate data.\n",
    "        client: BQ Client used to execute query.\n",
    "        Returns:\n",
    "        pd.DataFrame: A dataframe with the requested data.\n",
    "        \"\"\"\n",
    "        df = client.query(query).to_dataframe()\n",
    "        return df\n",
    "\n",
    "    dataframe = load_bq_data(get_query(bq_table), bq_client)\n",
    "    dataframe.to_csv(output_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03abc18d",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f1a3660",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\n",
    "        \"scikit-learn\",\n",
    "        \"pandas\",\n",
    "        \"joblib\",\n",
    "        \"tensorflow\"\n",
    "    ],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=f\"{AutoMLOps.OUTPUT_DIR}/train_model.yaml\",\n",
    ")\n",
    "def train_model(\n",
    "    output_model_directory: str,\n",
    "    dataset: Input[Dataset],\n",
    "    metrics: Output[Metrics],\n",
    "    model: Output[Model]\n",
    "):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.metrics import roc_curve\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from joblib import dump\n",
    "    import pandas as pd\n",
    "    import tensorflow as tf\n",
    "    import pickle\n",
    "    import os\n",
    "    \n",
    "    def save_model(model, uri):\n",
    "        \"\"\"Saves a model to uri.\"\"\"\n",
    "        with tf.io.gfile.GFile(uri, 'w') as f:\n",
    "            pickle.dump(model, f)\n",
    "    \n",
    "    df = pd.read_csv(dataset.path)\n",
    "    labels = df.pop(\"Class\").tolist()\n",
    "    data = df.values.tolist()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, labels)\n",
    "    skmodel = DecisionTreeClassifier()\n",
    "    skmodel.fit(x_train,y_train)\n",
    "    score = skmodel.score(x_test,y_test)\n",
    "    print('accuracy is:',score)\n",
    "    metrics.log_metric(\"accuracy\",(score * 100.0))\n",
    "    metrics.log_metric(\"framework\", \"Scikit Learn\")\n",
    "    metrics.log_metric(\"dataset_size\", len(df))\n",
    "\n",
    "    output_uri = os.path.join(output_model_directory, f'model.pkl')\n",
    "    save_model(skmodel, output_uri)\n",
    "    model.path = output_model_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae46f9f",
   "metadata": {},
   "source": [
    "## Uploading & Deploying the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa8047d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\n",
    "        \"google-cloud-aiplatform\"\n",
    "    ],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=f\"{AutoMLOps.OUTPUT_DIR}/deploy_model.yaml\",\n",
    ")\n",
    "def deploy_model(\n",
    "    model: Input[Model],\n",
    "    project: str,\n",
    "    region: str,\n",
    "    vertex_endpoint: Output[Artifact],\n",
    "    vertex_model: Output[Model]\n",
    "):\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project=project, location=region)\n",
    "    deployed_model = aiplatform.Model.upload(\n",
    "        display_name=\"beans-model-pipeline\",\n",
    "        artifact_uri = model.uri,\n",
    "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\"\n",
    "    )\n",
    "    endpoint = deployed_model.deploy(machine_type=\"n1-standard-4\")\n",
    "    vertex_endpoint.uri = endpoint.resource_name\n",
    "    vertex_model.uri = deployed_model.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3602954f",
   "metadata": {},
   "source": [
    "## Define and Run the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01996d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%define_kfp_pipeline\n",
    "\n",
    "@dsl.pipeline(name='training-pipeline')\n",
    "def pipeline(bq_table: str,\n",
    "             output_model_directory: str,\n",
    "             project: str,\n",
    "             region: str,\n",
    "            ):\n",
    "\n",
    "    dataset_task = create_dataset(\n",
    "        bq_table=bq_table, \n",
    "        project=project)\n",
    "\n",
    "    model_task = train_model(\n",
    "        output_model_directory=output_model_directory,\n",
    "        dataset=dataset_task.output)\n",
    "\n",
    "    deploy_task = deploy_model(\n",
    "        model=model_task.outputs[\"model\"],\n",
    "        project=project,\n",
    "        region=region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc244ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_params = {\n",
    "    \"bq_table\": f\"{PROJECT_ID}.test_dataset.dry-beans\",\n",
    "    \"output_model_directory\": f\"gs://{PROJECT_ID}-bucket/trained_models/{datetime.datetime.now()}\",\n",
    "    \"project\": f\"{PROJECT_ID}\",\n",
    "    \"region\": \"us-central1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36433503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32m Updating required API services in project automlops-sandbox \u001b[0m\n",
      "Operation \"operations/acat.p2-45373616427-ce04bc73-22b4-429d-80c5-5546406b4d5a\" finished successfully.\n",
      "\u001b[0;32m Checking for Artifact Registry: vertex-mlops-af in project automlops-sandbox \u001b[0m\n",
      "Listing items under project automlops-sandbox, location us-central1.\n",
      "\n",
      "vertex-mlops-af  DOCKER  STANDARD_REPOSITORY  Artifact Registry vertex-mlops-af in us-central1.  us-central1          Google-managed key  2023-01-11T17:12:26  2023-01-13T12:30:41  3905.859\n",
      "Artifact Registry: vertex-mlops-af already exists in project automlops-sandbox\n",
      "\u001b[0;32m Checking for GS Bucket: automlops-sandbox-bucket in project automlops-sandbox \u001b[0m\n",
      "gs://automlops-sandbox-bucket/\n",
      "GS Bucket: automlops-sandbox-bucket already exists in project automlops-sandbox\n",
      "\u001b[0;32m Checking for Service Account: vertex-pipelines in project automlops-sandbox \u001b[0m\n",
      "Pipeline Runner Service Account         vertex-pipelines@automlops-sandbox.iam.gserviceaccount.com  False\n",
      "Service Account: vertex-pipelines already exists in project automlops-sandbox\n",
      "\u001b[0;32m Updating required IAM roles in project automlops-sandbox \u001b[0m\n",
      "\u001b[0;32m Checking for Cloud Source Repository: AutoMLOps-repo in project automlops-sandbox \u001b[0m\n",
      "AutoMLOps-repo  automlops-sandbox  https://source.developers.google.com/p/automlops-sandbox/r/AutoMLOps-repo\n",
      "Cloud Source Repository: AutoMLOps-repo already exists in project automlops-sandbox\n",
      "Cloning Cloud Source Repository: AutoMLOps-repo\n",
      "Cloning into '/Users/srastatter/Documents/2023/MLOps-graduation/AutoMLOps/example/AutoMLOps-repo'...\n",
      "warning: remote HEAD refers to nonexistent ref, unable to checkout.\n",
      "\n",
      "Project [automlops-sandbox] repository [AutoMLOps-repo] was cloned to [/Users/srastatter/Documents/2023/MLOps-graduation/AutoMLOps/example/AutoMLOps-repo].\n",
      "Switched to a new branch 'automlops'\n",
      "\u001b[0;32m Checking for Cloudbuild Trigger: automlops-trigger in project automlops-sandbox \u001b[0m\n",
      "name: automlops-trigger\n",
      "Cloudbuild Trigger already exists in project automlops-sandbox for repo AutoMLOps-repo\n",
      "[automlops af9ca0a] Run AutoMLOps\n",
      " 2 files changed, 7 insertions(+), 62 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: It seems you're using Apple Git (git/2.37.1 (Apple Git-137.1),gzip(gfe),gzip(gfe)). Apple Git is not frequently updated and often has known vulnerabilities. Please follow the instructions at go/old-git-client#gmac to use a more current version of Git.        \n",
      "To https://source.developers.google.com/p/automlops-sandbox/r/AutoMLOps-repo\n",
      "   91dfb2c..af9ca0a  automlops -> automlops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushing code to automlops branch, triggering cloudbuild...\n",
      "Waiting for cloudbuild job to complete...............................Submitting PipelineJob...\n",
      "WARNING: This command is using service account impersonation. All API calls will be executed as [vertex-pipelines@automlops-sandbox.iam.gserviceaccount.com].\n",
      "\u001b[0;32m Submitting training job to Cloud Runner Service https://run-pipeline-q5owjmymra-uc.a.run.app using @pipelines/runtime_parameters/pipeline_parameter_values.json \u001b[0m\n",
      "Warning: --trace-ascii overrides an earlier trace/verbose option\n",
      "Note: Unnecessary use of -X or --request, POST is already inferred.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0== Info:   Trying 216.239.36.53:443...\n",
      "== Info: Connected to run-pipeline-q5owjmymra-uc.a.run.app (216.239.36.53) port 443 (#0)\n",
      "== Info: ALPN: offers http/1.1\n",
      "== Info:  CAfile: /etc/ssl/cert.pem\n",
      "== Info:  CApath: none\n",
      "== Info: (304) (OUT), TLS handshake, Client hello (1):\n",
      "=> Send SSL data, 338 bytes (0x152)\n",
      "0000: ...N...G..s.X.....p(#..n.(..d.H5..3.]. &.E..O....l$A.. .ywAB...*\n",
      "0040: .....)..b.............0.,.(.$.......k.9...........=.5...../.+.'.\n",
      "0080: #.......g.3...E...<./...A.......................+............3.&\n",
      "00c0: .$... .......gE..uo.f...!..S..)..&...K...).'..$run-pipeline-q5ow\n",
      "0100: jmymra-uc.a.run.app.............................................\n",
      "0140: ..........http/1.1\n",
      "== Info: (304) (IN), TLS handshake, Server hello (2):\n",
      "<= Recv SSL data, 122 bytes (0x7a)\n",
      "0000: ...v....n..D......F....7&@.>I..[....N. &.E..O....l$A.. .ywAB...*\n",
      "0040: .....).......3.$... .jM$.y.....Z...3..nV.. ...f..$.Z.+....\n",
      "== Info: (304) (IN), TLS handshake, Unknown (8):\n",
      "<= Recv SSL data, 21 bytes (0x15)\n",
      "0000: .............http/1.1\n",
      "== Info: (304) (IN), TLS handshake, Certificate (11):\n",
      "<= Recv SSL data, 4005 bytes (0xfa5)\n",
      "0000: ...........0...0..r.......?*.p......D.....0...*.H........0F1.0..\n",
      "0040: .U....US1\"0 ..U....Google Trust Services LLC1.0...U....GTS CA 1C\n",
      "0080: 30...221128081545Z..230220081544Z0.1.0...U....*.a.run.app0Y0...*\n",
      "00c0: .H.=....*.H.=....B......I....^...k.^R....8...\\..../Y.....n...0.}\n",
      "0100: .3l(.....<..^E...e.....m0..i0...U...........0...U.%..0...+......\n",
      "0140: .0...U.......0.0...U............g..^m...%rm...0...U.#..0....t...\n",
      "0180: ....=...F..q5.'0j..+........^0\\0'..+.....0...http://ocsp.pki.goo\n",
      "01c0: g/gts1c301..+.....0..%http://pki.goog/repo/certs/gts1c3.der0...U\n",
      "0200: ....0...*.a.run.app..run.app0!..U. ..0.0...g.....0...+.....y...0\n",
      "0240: <..U...50301./.-.+http://crls.pki.goog/gts1c3/zdATt0Ex_Fk.crl0..\n",
      "0280: ...+.....y............v.....|.....=..>.j.g)]...$...4............\n",
      "02c0: .....G0E. S.....:;u.......`Atj.h..Rb*...B..!...r......B?.o..3..G\n",
      "0300: .......Z..t...v..sw...P.c.......Jy-.g.......y6...............G0E\n",
      "0340: .!..r......-.A_(..qV..?..[..l..BHk.. ........E........$..$.B?...\n",
      "0380: ..*..0...*.H...............[=o..3...........*X...54%i.N........b\n",
      "03c0: N..........(..q..b.N....-..8........9..E?}......`.6....m2,...<..\n",
      "0400: ....]....[..0..._P{1PoAx........lG7..........]/...,:.[....*).)s.\n",
      "0440: .s.:...G.\\.YJ.X5F...?X?.#I.UM.kE .Z6O...(n....\"........3.Va..o..\n",
      "0480: .~.E|..RKz@.@..\"..M*js..s.....0...0..~..........SYk4....Pf0...*.\n",
      "04c0: H........0G1.0...U....US1\"0 ..U....Google Trust Services LLC1.0.\n",
      "0500: ..U....GTS Root R10...200813000042Z..270930000042Z0F1.0...U....U\n",
      "0540: S1\"0 ..U....Google Trust Services LLC1.0...U....GTS CA 1C30..\"0.\n",
      "0580: ..*.H.............0............b..7.7B..l...e.%...k..m.Z#.......\n",
      "05c0: ..|....B.^V$.z3....i..t.WLfh.w7US.9.M.4._%w7;...<......C...G..D.\n",
      "0600: c..A..A0H......E.!..B...+eV4.&....}....H|7M?.....u..yW\\.Wn......\n",
      "0640: ...%...,...*....c.<PI...._.+Y.....Q..w....O.pI.\\m .......w.-...k\n",
      "0680: ....+........'....Q.................0..|0...U...........0...U.%.\n",
      "06c0: .0...+.........+.......0...U.......0.......0...U.......t.......=\n",
      "0700: ...F..q5.'0...U.#..0.....+&q.+H'./Rf,....q>0h..+........\\0Z0&..+\n",
      "0740: .....0...http://ocsp.pki.goog/gtsr100..+.....0..$http://pki.goog\n",
      "0780: /repo/certs/gtsr1.der04..U...-0+0).'.%.#http://crl.pki.goog/gtsr\n",
      "07c0: 1/gtsr1.crl0W..U. .P0N08..+.....y...0*0(..+.........https://pki.\n",
      "0800: goog/repository/0...g.....0...g.....0...*.H..............}. \\.<.\n",
      "0840: ..W.......rq.6...@..L.F...$..Pq\"...n...jo......_.l.......b....[.\n",
      "0880: f.........i>z.FI_F.A...Me4...?O.l.I..SA..!.....D[*P..M.S6.B..T..\n",
      "08c0: wS.d8'...X..|9-[..........S$....y.&.a.SR.B..f+?...........q.5($.\n",
      "0900: ....-.H.=Y.Q.t..|...[..4...........\"....q....s$.7S...?..\\.6..;.)\n",
      "0940: ...:b;lc...Yq.c'.L....s..*....l2.3...Qq.4...].QX......Y.q..M(..m\n",
      "0980: ......F...k.w.....#.........D..u#.4.. ..^...RF.....!pQ.....U.+.3\n",
      "09c0: w.KB..w..s.....7?..*f.s.2.2l2....#.[}Mep.+.=...m.2.....c...]...q\n",
      "0a00: ^*...\"..e:...e.....[.Y.G.-.$:...&....7..o....Q.......Q......f0..\n",
      "0a40: b0..J.......w..l.6...!...X..0...*.H........0W1.0...U....BE1.0...\n",
      "0a80: U....GlobalSign nv-sa1.0...U....Root CA1.0...U....GlobalSign Roo\n",
      "0ac0: t CA0...200619000042Z..280128000042Z0G1.0...U....US1\"0 ..U....Go\n",
      "0b00: ogle Trust Services LLC1.0...U....GTS Root R10..\"0...*.H........\n",
      "0b40: .....0...............w.;...>...@<....}2..q........j.....K.+.....\n",
      "0b80: ..............^..R..#'....c...~..^.h...ZG.M.3.N.....lK......d)%#\n",
      "0bc0: ....=.`.......H.M..z.....Y........1.......ml....~&.E.=.y..(...&.\n",
      "0c00: .....<h.S..:.+.....z..u....Vd..Oh.=......@..\\....5l..P...L... .3\n",
      "0c40: .R..2.).%*.H.r..d...........8f..c...x.{\\w.v......y.W..&.........\n",
      "0c80: .....U.....K)...2%N*.eD.....I...|..@{.C..l..}...L......K.....E.v\n",
      "0cc0: ..@+.S....;......1..w.o{>...\".....2..c.Qr.]....)h3.:f...&...Wex'\n",
      "0d00: .^I.......!............lH<@.~.Z.V<.....K.9K..?.U.n$..q..........\n",
      "0d40: A...=:..z.7...........80..40...U...........0...U.......0....0...\n",
      "0d80: U........+&q.+H'./Rf,....q>0...U.#..0...`{f.E....P/}..4....K0`..\n",
      "0dc0: +........T0R0%..+.....0...http://ocsp.pki.goog/gsr10)..+.....0..\n",
      "0e00: .http://pki.goog/gsr1/gsr1.crt02..U...+0)0'.%.#.!http://crl.pki.\n",
      "0e40: goog/gsr1/gsr1.crl0;..U. .4020...g.....0...g.....0...+.....y....\n",
      "0e80: 0...+.....y....0...*.H.............4...(...v..1z!..R>..t.A..=5..\n",
      "0ec0: ....\\_...|......W.&o[..Fh.7okz...7.%Q..h...I.Z...#...+.....Ij.u.\n",
      "0f00: ......XHW.5.....o..o.......*..Ni..-.h..+s....\".7..f.I..U.g.2..&.\n",
      "0f40: p.=.gm=|.4..2..n.jo.....K.;..7..D.~.l..F.....!.f...Ul.)...f[.wIH\n",
      "0f80: (....3rS..5.b..$...9..~*A.R.......?..\n",
      "== Info: (304) (IN), TLS handshake, CERT verify (15):\n",
      "<= Recv SSL data, 78 bytes (0x4e)\n",
      "0000: ...J...F0D. $...\"..z.;......(..nf.7H...H_.q.. .......A..........\n",
      "0040: ..jM.r.....P%.\n",
      "== Info: (304) (IN), TLS handshake, Finished (20):\n",
      "<= Recv SSL data, 36 bytes (0x24)\n",
      "0000: ... ........f..<`a..=p..)......-SJ..\n",
      "== Info: (304) (OUT), TLS handshake, Finished (20):\n",
      "=> Send SSL data, 36 bytes (0x24)\n",
      "0000: ... !.Iv,..&.V.....d...Z)..,...q.I..\n",
      "== Info: SSL connection using TLSv1.3 / AEAD-CHACHA20-POLY1305-SHA256\n",
      "== Info: ALPN: server accepted http/1.1\n",
      "== Info: Server certificate:\n",
      "== Info:  subject: CN=*.a.run.app\n",
      "== Info:  start date: Nov 28 08:15:45 2022 GMT\n",
      "== Info:  expire date: Feb 20 08:15:44 2023 GMT\n",
      "== Info:  subjectAltName: host \"run-pipeline-q5owjmymra-uc.a.run.app\" matched cert's \"*.a.run.app\"\n",
      "== Info:  issuer: C=US; O=Google Trust Services LLC; CN=GTS CA 1C3\n",
      "== Info:  SSL certificate verify ok.\n",
      "=> Send header, 869 bytes (0x365)\n",
      "0000: POST / HTTP/1.1\n",
      "0011: Host: run-pipeline-q5owjmymra-uc.a.run.app\n",
      "003d: User-Agent: curl/7.85.0\n",
      "0056: Accept: */*\n",
      "0063: Authorization:bearer eyJhbGciOiJSUzI1NiIsImtpZCI6ImEyOWFiYzE5YmU\n",
      "00a3: yN2ZiNDE1MWFhNDMxZTk0ZmEzNjgwYWU0NThkYTUiLCJ0eXAiOiJKV1QifQ.eyJh\n",
      "00e3: dWQiOiJodHRwczovL3J1bi1waXBlbGluZS1xNW93am15bXJhLXVjLmEucnVuLmFw\n",
      "0123: cCIsImF6cCI6IjEwMDQ4MDUwMjkzMDQyNDQ4NTM0NCIsImV4cCI6MTY3MzYzNTM1\n",
      "0163: NiwiaWF0IjoxNjczNjMxNzU2LCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2ds\n",
      "01a3: ZS5jb20iLCJzdWIiOiIxMDA0ODA1MDI5MzA0MjQ0ODUzNDQifQ.YK841ImjUxgJi\n",
      "01e3: qVXOALbOwgkZ1gLdsdndPKZ32XTIXy2P_N0V4A_gJNGnsNz8TIWO4FUVb7cT1DRk\n",
      "0223: 9RldRkiEYTOOzx2LLMULomSc0P02geffe53ejfFK3FfABgMgL1F_O88Psnz_1fzC\n",
      "0263: K0KsvYfEFhWsQLRwSwdHfwvxN_E82Y4qXucjzi-PQ33D1C_Qpr-fzUIXQnpehMIx\n",
      "02a3: e9gN8Nn4fR16DcZNOH9mJSkt3IxIJkQjLMxWAy71gO2LgI7pOwnuWJmWPJRtj-ae\n",
      "02e3: 9tvtYzxyeyK-IbVyKz1FpTwSnmGuiCLq5_E4mJ491hRtWfXn7oXUyyo7CVHWGRc2\n",
      "0323: Iq0U-HbtQ\n",
      "032e: Content-Type: application/json\n",
      "034e: Content-Length: 227\n",
      "0363: \n",
      "=> Send data, 227 bytes (0xe3)\n",
      "0000: {    \"bq_table\": \"automlops-sandbox.test_dataset.dry-beans\",    \n",
      "0040: \"output_model_directory\": \"gs://automlops-sandbox-bucket/trained\n",
      "0080: _models/2023-01-13 12:34:00.146157\",    \"project\": \"automlops-sa\n",
      "00c0: ndbox\",    \"region\": \"us-central1\"}\n",
      "100   227    0     0  100   227      0     36  0:00:06  0:00:06 --:--:--     0== Info: Mark bundle as not supporting multiuse\n",
      "<= Recv header, 17 bytes (0x11)\n",
      "0000: HTTP/1.1 200 OK\n",
      "<= Recv header, 32 bytes (0x20)\n",
      "0000: content-type: application/json\n",
      "<= Recv header, 61 bytes (0x3d)\n",
      "0000: X-Cloud-Trace-Context: 99a18aa3a0f8a52007f38d6b1934ef7a;o=1\n",
      "<= Recv header, 37 bytes (0x25)\n",
      "0000: Date: Fri, 13 Jan 2023 17:42:42 GMT\n",
      "<= Recv header, 25 bytes (0x19)\n",
      "0000: Server: Google Frontend\n",
      "<= Recv header, 21 bytes (0x15)\n",
      "0000: Content-Length: 260\n",
      "<= Recv header, 173 bytes (0xad)\n",
      "0000: Alt-Svc: h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000,h3-Q050=\n",
      "0040: \":443\"; ma=2592000,h3-Q046=\":443\"; ma=2592000,h3-Q043=\":443\"; ma\n",
      "0080: =2592000,quic=\":443\"; ma=2592000; v=\"46,43\"\n",
      "<= Recv header, 2 bytes (0x2)\n",
      "0000: \n",
      "<= Recv data, 260 bytes (0x104)\n",
      "0000: {\"dashboard_uri\":\"https://console.cloud.google.com/vertex-ai/loc\n",
      "0040: ations/us-central1/pipelines/runs/training-pipeline-202301131742\n",
      "0080: 42?project=45373616427\",\"resource_name\":\"projects/45373616427/lo\n",
      "00c0: cations/us-central1/pipelineJobs/training-pipeline-2023011317424\n",
      "0100: 2\"}.\n",
      "100   487  100   260  100   227     40     35  0:00:06  0:00:06 --:--:--    80\n",
      "{\"dashboard_uri\":\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/training-pipeline-20230113174242?project=45373616427\",\"resource_name\":\"projects/45373616427/locations/us-central1/pipelineJobs/training-pipeline-20230113174242\"}\n",
      "== Info: Connection #0 to host run-pipeline-q5owjmymra-uc.a.run.app left intact\n",
      "Creating Cloud Scheduler Job\n",
      "\u001b[0;32m Checking for Cloud Scheduler Job: AutoMLOps-schedule in project automlops-sandbox \u001b[0m\n",
      "AutoMLOps-schedule  us-central1  0 */12 * * * (Etc/UTC)  HTTP         ENABLED\n",
      "Cloud Scheduler AutoMLOps resource already exists in project automlops-sandbox or Cloud Runner service not found\n",
      "\n",
      "#################################################################\n",
      "#                                                               #\n",
      "#                       RESOURCES MANIFEST                      #\n",
      "#---------------------------------------------------------------#\n",
      "#     Generated resources can be found at the following urls    #\n",
      "#                                                               #\n",
      "#################################################################\n",
      "\n",
      "Google Cloud Storage Bucket: https://console.cloud.google.com/storage/automlops-sandbox-bucket\n",
      "Artifact Registry: https://console.cloud.google.com/artifacts/docker/automlops-sandbox/us-central1/vertex-mlops-af\n",
      "Service Accounts: https://console.cloud.google.com/iam-admin/serviceaccounts?project=automlops-sandbox\n",
      "APIs: https://console.cloud.google.com/apis\n",
      "Cloud Source Repository: https://source.cloud.google.com/automlops-sandbox/AutoMLOps-repo/+/automlops:\n",
      "Cloud Build Jobs: https://console.cloud.google.com/cloud-build/builds\n",
      "Vertex AI Pipeline Runs: https://console.cloud.google.com/vertex-ai/pipelines/runs\n",
      "Cloud Build Trigger: https://console.cloud.google.com/cloud-build/triggers;region=us-central1\n",
      "Cloud Run Service: https://console.cloud.google.com/run/detail/us-central1/run-pipeline\n",
      "Cloud Scheduler Job: https://console.cloud.google.com/cloudscheduler\n"
     ]
    }
   ],
   "source": [
    "AutoMLOps.go(project_id=PROJECT_ID, pipeline_params=pipeline_params, use_kfp_spec=True, run_local=False, schedule_pattern='0 */12 * * *')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47354dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
